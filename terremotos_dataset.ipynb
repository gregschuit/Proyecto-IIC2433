{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Semestral - Entrega final\n",
    "\n",
    "Luciano Davico  \n",
    "Gregory Schuit  \n",
    "\n",
    "En el presente notebook se presenta el an치lisis de datos sobre terremotos y tsunamis, especificamente mediante la implementaci칩n de un Random Forest para poder discriminar entre terremotos que ocasionan tsunamis y los que no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time, sleep\n",
    "from IPython.core.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['time', 'latitude', 'longitude', 'depth', 'mag', 'magType', 'nst',\n",
       "       'gap', 'dmin', 'rms', 'net', 'id', 'updated', 'place', 'type',\n",
       "       'horizontalError', 'depthError', 'magError', 'magNst', 'status',\n",
       "       'locationSource', 'magSource'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos los datos de terremotos y filtramos las features.\n",
    "quakes_df = pd.read_csv('Data/quakes.csv')\n",
    "print(len(quakes_df))\n",
    "quakes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.6457</td>\n",
       "      <td>20.8702</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2018-10-27T18:33:12.420Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.2234</td>\n",
       "      <td>-151.6636</td>\n",
       "      <td>16.60</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2018-10-27T16:57:27.956Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-22.4704</td>\n",
       "      <td>-68.6516</td>\n",
       "      <td>113.79</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2018-10-27T15:46:43.390Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-56.0652</td>\n",
       "      <td>-27.4276</td>\n",
       "      <td>93.78</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2018-10-27T15:00:46.800Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.3128</td>\n",
       "      <td>20.4930</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2018-10-27T14:33:26.470Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude   depth  mag                      time\n",
       "0   37.6457    20.8702   10.00  4.7  2018-10-27T18:33:12.420Z\n",
       "1   65.2234  -151.6636   16.60  5.3  2018-10-27T16:57:27.956Z\n",
       "2  -22.4704   -68.6516  113.79  4.7  2018-10-27T15:46:43.390Z\n",
       "3  -56.0652   -27.4276   93.78  4.9  2018-10-27T15:00:46.800Z\n",
       "4   37.3128    20.4930   10.00  4.6  2018-10-27T14:33:26.470Z"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quakes_df = quakes_df[['latitude', 'longitude', 'depth', 'mag', 'time']]\n",
    "quakes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1900-07-29T06:59:00.000Z'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(quakes_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_MAGNITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>6.6</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>7.1</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>6.9</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>8.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>6.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PRIMARY_MAGNITUDE  LATITUDE  LONGITUDE  YEAR\n",
       "372                6.6      -4.0      152.0  1900\n",
       "373                7.1      -5.0      148.0  1900\n",
       "374                6.9      -4.0      140.0  1900\n",
       "375                8.4      11.0      -66.0  1900\n",
       "376                6.0      39.0      143.0  1901"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos los dato de tsunamis y seleccionamos las features\n",
    "tsunamis_df = pd.read_csv('Data/tsunamis.tsv', sep='\\t', encoding='iso-8859-1')\n",
    "tsunamis_df = tsunamis_df[tsunamis_df['YEAR'] >= 1900]\n",
    "tsunamis_df = tsunamis_df[['PRIMARY_MAGNITUDE', 'LATITUDE', 'LONGITUDE', 'YEAR']]\n",
    "print(len(tsunamis_df))\n",
    "tsunamis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posibe observar que existen 415677 terremotos y tan solo 1145 tsunamis. Este problema de desbalance se nivelar치 filtrando intervalos con muchos terremotos y pocos tsunamis, es decir, el rango de magnitudes bajas. A continuaci칩n observaremos los datos para determinar un punto de corte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAADFCAYAAABnw+dWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAD8dJREFUeJzt3W+MXNV5x/HvU1yE7Q2YP8mK2rRLFYsmYtUWVpQECa3jpAIcxbQCiYimNqLaqiLUTVwpbt/wKqqRSlMqVZEsnMaVKBviEIHqhIJcNikvsLIG2gWcypQ4xsaxiQJOl1iCrZ6+2Gt1a9by7MycvTN7vx/Jmpk7Z+Y+3rN35rfn3D+RmUiSJKm7fqnuAiRJkpYiQ5YkSVIBhixJkqQCDFmSJEkFGLIkSZIKMGRJkiQVYMiSJEkqwJAlSZJUgCFLkiSpgGV1FwBw2WWX5dDQUN1lNM4777zDypUr6y6j0eyD3mA/1M8+6A32Q2v279//08z84Lna9UTIGhoaYnJysu4yGmdiYoLR0dG6y2g0+6A32A/1sw96g/3Qmoj4cSvtnC6UJEkq4JwhKyK+FhEnIuKlOcsuiYinI+JgdXtxtTwi4u8i4tWI+I+IuKZk8ZIkSb2qlZGsrwM3nbFsG7A3M9cCe6vHADcDa6t/Y8BXu1OmJElSfzlnyMrM7wM/O2PxRmBXdX8XcOuc5f+Ys54DVkXE5d0qVpIkqV+0u+P7YGYeA8jMYxHxoWr5auD1Oe2OVMuOnfkGETHG7GgXg4ODTExMtFmK2jU9Pe3PvWb2QW+wH+pnH/QG+6G7un10YcyzLOdrmJk7gB0AIyMj6dEMi8+jSOpnH5Q1tG1PS+22Dv8PDzz7DgCHtm8oWZLOwm2hN9gP3dXu0YXHT08DVrcnquVHgCvmtFsDvNF+eZIkSf2p3ZD1BLCpur8JeHzO8j+sjjK8Hjh5elpRkiSpSc45XRgRjwCjwGURcQS4D9gOPBoRdwOHgdur5t8BbgFeBX4B3FWgZkmSpJ53zpCVmZ89y1Pr52mbwD2dFiVJktTvPOO7JElSAYYsSZKkAgxZkiRJBRiyJEmSCjBkSZIkFWDIkiRJKsCQJUmSVIAhS5IkqQBDliRJUgGGLEmSpAIMWZIkSQUYsiRJkgowZEmSJBVgyJIkSSrAkCVJklSAIUuSJKkAQ5YkSVIBhixJkqQCDFmSJEkFGLIkSZIKMGRJkiQVYMiSJEkqoKOQFRFfiIiXI+KliHgkIi6IiCsjYl9EHIyIb0TE+d0qVpIkqV+0HbIiYjXwp8BIZl4NnAfcAdwPfCUz1wJvAXd3o1BJkqR+0ul04TJgeUQsA1YAx4BPALur53cBt3a4DkmSpL4Tmdn+iyO2AF8GTgFPAVuA5zLzw9XzVwDfrUa6znztGDAGMDg4eO34+Hjbdag909PTDAwM1F1Go9kHZU0dPdlSu8HlcPzU7P3h1RcVrEhn47bQG+yH1qxbt25/Zo6cq92ydlcQERcDG4ErgbeBbwI3z9N03hSXmTuAHQAjIyM5Ojrabilq08TEBP7c62UflLV5256W2m0dnuGBqdmPw0N3jhasSGfjttAb7Ifu6mS68JPAjzLzzcx8D3gM+Diwqpo+BFgDvNFhjZIkSX2n7ZEs4DBwfUSsYHa6cD0wCTwD3AaMA5uAxzstUpJU3lCLI39zHdq+oUAl0tLQ9khWZu5jdgf354Gp6r12AF8CvhgRrwKXAju7UKckSVJf6WQki8y8D7jvjMWvAdd18r6SJEn9zjO+S5IkFWDIkiRJKsCQJUmSVIAhS5IkqQBDliRJUgGGLEmSpAIMWZIkSQUYsiRJkgowZEmSJBVgyJIkSSrAkCVJklSAIUuSJKkAQ5YkSVIBhixJkqQCDFmSJEkFLKu7AElqmqFtexb8mkPbNxSoRFJJjmRJkiQVYMiSJEkqwJAlSZJUgCFLkiSpAEOWJElSAYYsSZKkAgxZkiRJBXQUsiJiVUTsjogfRsSBiPhYRFwSEU9HxMHq9uJuFStJktQvOh3JehB4MjN/A/hN4ACwDdibmWuBvdVjSZKkRmk7ZEXEhcCNwE6AzHw3M98GNgK7qma7gFs7LVKSJKnfRGa298KI3wJ2AK8wO4q1H9gCHM3MVXPavZWZ75syjIgxYAxgcHDw2vHx8bbqUPump6cZGBiou4xGsw/Kmjp6sqV2g8vh+KnZ+8OrLypY0axW65prqdflttAb7IfWrFu3bn9mjpyrXSchawR4DrghM/dFxIPAz4F7WwlZc42MjOTk5GRbdah9ExMTjI6O1l1Go9kHZbV6jcCtwzM8MDV7KdfFuEZgr167sM663BZ6g/3QmohoKWR1sk/WEeBIZu6rHu8GrgGOR8TlVRGXAyc6WIckSVJfajtkZeZPgNcj4qpq0Xpmpw6fADZVyzYBj3dUoSRJUh9a1uHr7wUejojzgdeAu5gNbo9GxN3AYeD2DtchSZLUdzoKWZn5IjDfnOT6Tt5XkiSp33nGd0mSpAIMWZIkSQUYsiRJkgowZEmSJBVgyJIkSSrAkCVJklSAIUuSJKkAQ5YkSVIBhixJkqQCDFmSJEkFGLIkSZIK6PQC0ZKWmKFtexb8mkPbNxSoRJL6myNZkiRJBRiyJEmSCnC6UJI60M70qqRmcCRLkiSpAEOWJElSAYYsSZKkAgxZkiRJBbjjuyT1gYXuYO+5y6T6OZIlSZJUgCFLkiSpgI5DVkScFxEvRMQ/V4+vjIh9EXEwIr4REed3XqYkSVJ/6cZI1hbgwJzH9wNfycy1wFvA3V1YhyRJUl/pKGRFxBpgA/BQ9TiATwC7qya7gFs7WYckSVI/isxs/8URu4G/Aj4A/DmwGXguMz9cPX8F8N3MvHqe144BYwCDg4PXjo+Pt12H2jM9Pc3AwEDdZTRaL/bB1NGTC37N8OqLClTSuVb/L4PL4fipwsUsUd3q+17cFprIfmjNunXr9mfmyLnatX0Kh4j4NHAiM/dHxOjpxfM0nTfFZeYOYAfAyMhIjo6OztdMBU1MTODPvV692Aeb27gW36E7R7tfSBe0+n/ZOjzDA1Oe0aYd3er7XtwWmsh+6K5OPlVuAD4TEbcAFwAXAn8LrIqIZZk5A6wB3ui8TEmSpP7S9j5ZmfkXmbkmM4eAO4B/zcw7gWeA26pmm4DHO65SkiSpz5Q4T9aXgC9GxKvApcDOAuuQJEnqaV3ZCSEzJ4CJ6v5rwHXdeF9JkqR+5RnfJUmSCjBkSZIkFeAxy5JqMbTAU0Uc2r6hUCWSVIYjWZIkSQUYsiRJkgowZEmSJBVgyJIkSSrAkCVJklSAIUuSJKkAQ5YkSVIBnidLUl9Y6Hm1tDja6RfPeaamMGRJNRnatoetwzNsXsCXlF9OktQ/nC6UJEkqwJEsSR1zKk+S3s+RLEmSpAIMWZIkSQU4XShJWnI86lG9wJEsSZKkAgxZkiRJBRiyJEmSCjBkSZIkFWDIkiRJKqDtkBURV0TEMxFxICJejogt1fJLIuLpiDhY3V7cvXIlSZL6QycjWTPA1sz8CHA9cE9EfBTYBuzNzLXA3uqxJElSo7QdsjLzWGY+X93/b+AAsBrYCOyqmu0Cbu20SEmSpH4Tmdn5m0QMAd8HrgYOZ+aqOc+9lZnvmzKMiDFgDGBwcPDa8fHxjuvQwkxPTzMwMFB3GY01dfQkg8vh+KnWXzO8+qJyBVWmjp4svo5es9B+UGfm+z3u9udRO7/Hi7F99Tq/F1qzbt26/Zk5cq52HYesiBgAvgd8OTMfi4i3WwlZc42MjOTk5GRHdWjhJiYmGB0drbuMxhratoetwzM8MNX6hRcW44zUTbzY80L7QZ2Z7/e4259HnvG9PX4vtCYiWgpZHR1dGBG/DHwLeDgzH6sWH4+Iy6vnLwdOdLIOSZKkftTJ0YUB7AQOZObfzHnqCWBTdX8T8Hj75UmSJPWnTsbHbwA+B0xFxIvVsr8EtgOPRsTdwGHg9s5KlCRJ6j9th6zMfBaIszy9vt33ldRdTdzHSkuLv8PqV57xXZIkqQAPp5EkLar5Rqa2Ds+w2RErLTGOZEmSJBVgyJIkSSrAkCVJklSAIUuSJKkAQ5YkSVIBhixJkqQCDFmSJEkFGLIkSZIK8GSkUh/x8iKS1D8cyZIkSSrAkSz1ncUYzTm0fUPxdUiSljZHsiRJkgowZEmSJBXgdKHOaqHTck6xSZL0fwxZ0jw8ik+S1CmnCyVJkgpwJEuSpEXSzii5u2L0L0eyJEmSCnAkqyHm++tp6/AMm7u475H7MUnqZx7so25rTMhyiFaSpPmd/o5cyB/ffkeem9OFkiRJBRQZyYqIm4AHgfOAhzJze4n1SJJUl8XaRcJpzP7V9ZAVEecBfw98CjgC/CAinsjMV7q9rtK8Rp4kSfXp9119SkwXXge8mpmvZea7wDiwscB6JEmSelZkZnffMOI24KbM/KPq8eeA38nMz5/RbgwYqx5eBfxnVwtRKy4Dflp3EQ1nH/QG+6F+9kFvsB9a82uZ+cFzNSqxT1bMs+x9SS4zdwA7CqxfLYqIycwcqbuOJrMPeoP9UD/7oDfYD91VYrrwCHDFnMdrgDcKrEeSJKlnlQhZPwDWRsSVEXE+cAfwRIH1SJIk9ayuTxdm5kxEfB74F2ZP4fC1zHy52+tRVzhdWz/7oDfYD/WzD3qD/dBFXd/xXZIkSZ7xXZIkqQhDliRJUgGGrAaKiEMRMRURL0bEZN31NFVErIqI3RHxw4g4EBEfq7umJomIq6pt4PS/n0fEn9VdVxNFxBci4uWIeCkiHomIC+quqWkiYkv183/Z7aB73CergSLiEDCSmZ5wrkYRsQv4t8x8qDoSd0Vmvl13XU1UXQ7sKLMnTv5x3fU0SUSsBp4FPpqZpyLiUeA7mfn1eitrjoi4mtmrs1wHvAs8CfxJZh6stbAlwJEsqQYRcSFwI7ATIDPfNWDVaj3wXwas2iwDlkfEMmAFnltxsX0EeC4zf5GZM8D3gN+ruaYlwZDVTAk8FRH7q8sbafH9OvAm8A8R8UJEPBQRK+suqsHuAB6pu4gmysyjwF8Dh4FjwMnMfKreqhrnJeDGiLg0IlYAt/D/TyquNhmymumGzLwGuBm4JyJurLugBloGXAN8NTN/G3gH2FZvSc1UTdV+Bvhm3bU0UURcDGwErgR+BVgZEX9Qb1XNkpkHgPuBp5mdKvx3YKbWopYIQ1YDZeYb1e0J4NvMzsNrcR0BjmTmvurxbmZDlxbfzcDzmXm87kIa6pPAjzLzzcx8D3gM+HjNNTVOZu7MzGsy80bgZ4D7Y3WBIathImJlRHzg9H3gd5kdKtYiysyfAK9HxFXVovXAKzWW1GSfxanCOh0Gro+IFRERzG4LB2quqXEi4kPV7a8Cv4/bRFd0/bI66nmDwLdnP8tYBvxTZj5Zb0mNdS/wcDVd9RpwV831NE61/8mngD+uu5amysx9EbEbeJ7ZKaoX8NIudfhWRFwKvAfck5lv1V3QUuApHCRJkgpwulCSJKkAQ5YkSVIBhixJkqQCDFmSJEkFGLIkSZIKMGRJkiQVYMiSJEkq4H8B++Uo2OSE2YAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observamos distribuciones de la magnitud\n",
    "hist1 = tsunamis_df['PRIMARY_MAGNITUDE'].hist(bins=40, figsize=(10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist2 = quakes_df['mag'].hist(bins=40, figsize=(10, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los histogramas, es posible apreciar que la gran mayoria de los terremotos bajo 6 grados aproximadamente, no genera tsunami alguno. Por esta raz칩n es que lo consideraremos como el punto de corte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663\n",
      "4930\n"
     ]
    }
   ],
   "source": [
    "corte = 6.3\n",
    "print(len(tsunamis_df[tsunamis_df['PRIMARY_MAGNITUDE'] > corte]))\n",
    "print(len(quakes_df[quakes_df['mag'] > corte]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsunamis_df = tsunamis_df[tsunamis_df['PRIMARY_MAGNITUDE'] > corte]\n",
    "quakes_df = quakes_df[quakes_df['mag'] > corte]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join\n",
    "Ahora, procederemos a hacer el join de ambas tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds left: 2.672\r"
     ]
    }
   ],
   "source": [
    "# Creamos una nueva columna en el dataset de terremotos,\n",
    "# que por defecto ser치 la ausencia de tsunami.\n",
    "quakes_df['tsunami'] = 0\n",
    "\n",
    "t0, i, total = time(), 0, len(quakes_df)\n",
    "for index, row in quakes_df.iterrows():  # Para cada terremoto, se busca la correspondencia\n",
    "    lat = row['latitude']                # en la tabla tsunamis.\n",
    "    lon = row['longitude']\n",
    "    mag = row['mag']\n",
    "    year = int(row['time'][:4])\n",
    "    \n",
    "    delta_pos = 2.5  # valores tuneados a mano para el margen de error.\n",
    "    delta_mag = 0.3\n",
    "    \n",
    "    cond1 = abs(tsunamis_df['LATITUDE'] - lat) < delta_pos\n",
    "    cond2 = abs(tsunamis_df['LONGITUDE'] - lon) < delta_pos\n",
    "    cond3 = abs(tsunamis_df['PRIMARY_MAGNITUDE'] - mag) < delta_mag\n",
    "    cond4 = tsunamis_df['YEAR'] == year\n",
    "    \n",
    "    # Si existe un elemento en la tabla de tsunamis con las features muy cercanas,\n",
    "    # se le asocia al terremoto.\n",
    "    if len(tsunamis_df.loc[cond1 & cond2 & cond3 & cond4]) >= 1:\n",
    "        quakes_df.at[index, 'tsunami'] = 1\n",
    "    else:\n",
    "        quakes_df.at[index, 'tsunami'] = 0\n",
    "    \n",
    "    i += 1\n",
    "    if i % 80 == 0:\n",
    "        print('Seconds left: {:.2f}'.format((time() - t0)/i * (total - i)), end='\\r')\n",
    "\n",
    "print('Total time: {:.2f}'.format(time() - t0))\n",
    "len(quakes_df[quakes_df['tsunami'] == 1]), len(tsunamis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magnitudes de todos los terremotos\n",
    "hist3 = quakes_df['mag'].hist(bins=31, figsize=(12,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magnitudes de terremotos que provocaron tsunamis\n",
    "hist4 = quakes_df[quakes_df['tsunami'] == 1]['mag'].hist(bins=30, figsize=(12,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las siguientes visualizaciones, trataremos de situar los eventos en un scatter plot con respecto a las coordenadas en el globo terrestre, y asi poder tener ideas sobre la distribucion de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = quakes_df['longitude']\n",
    "y = quakes_df['latitude']\n",
    "\n",
    "area = 10\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(x, y, s=area, marker='o', c=1-quakes_df['tsunami'], alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver en el scatter plot, que si pintamos los terremotos que no causan tsunami de amarillo, y los que s칤 causan tsunami de morado, se trazan las zonas m치s s칤smicas del planeta. Los puntos amarillos logran mostrar, a la izquierda de la visualizaci칩n, la frontera oeste del continente americano, mientras que a la derecha podemos distinguir la frontera este de Asia y la polinesia. Por conocimiento general, esperabamos esto ya que estas zonas son el l칤mite de la placa tect칩nica del pac칤fico, zona donde los volcanes y s칤smos abundan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = quakes_df['mag']\n",
    "y = quakes_df['depth']\n",
    "\n",
    "area = 10 # 0 to 10 point radii\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(x, y, s=area, marker='o', c=1-quakes_df['tsunami'], alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, accuracy_score, \\\n",
    "                            classification_report\n",
    "\n",
    "# Definimos un decorador para tomar el tiempo de las funciones\n",
    "def timer(f_in):\n",
    "    def f_out(*args, **kwargs):\n",
    "        t0 = time()\n",
    "        ret = f_in(*args, **kwargs)\n",
    "        print(\"Total time spent: {:.2f}s\".format(time() - t0), end='\\r')\n",
    "        return ret\n",
    "    return f_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos matriz de features y vector de clase\n",
    "quakes_features = quakes_df[['latitude', 'longitude', 'depth', 'mag']]\n",
    "target = quakes_df['tsunami']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST #\n",
    "@timer\n",
    "def fitRandomForest(X, y, seed=0):\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=75, max_depth=10, \n",
    "                                 class_weight='balanced' , random_state=seed)\n",
    "    trained = clf.fit(X, y)\n",
    "    \n",
    "    return trained\n",
    "\n",
    "\n",
    "# REGRESI칍N LOG칈STICA #\n",
    "@timer\n",
    "def fitRegresionLogistica(X, y, seed=0):\n",
    "    \n",
    "    clf = LogisticRegression(class_weight='balanced', \n",
    "                             random_state=seed)  # Con este par치metro se ajustan los pesos seg칰n la frecuencia de la clase\n",
    "    trained = clf.fit(X, y)\n",
    "    \n",
    "    return trained\n",
    "\n",
    "\n",
    "# SUPPORT VECTOR MACHINE #\n",
    "@timer\n",
    "def fitSupportVectorMachine(X, y, C=1, seed=0):\n",
    "    \n",
    "    clf = SVC(C=C,  # Valor de la penalizaci칩n \n",
    "              kernel='sigmoid', class_weight='balanced', \n",
    "              probability=True, random_state=seed)\n",
    "    trained = clf.fit(X, y)\n",
    "    \n",
    "    return trained\n",
    "\n",
    "\n",
    "# NEURAL NETWORK\n",
    "@timer\n",
    "def fitNeuralNetwork(X, y, seed=0):\n",
    "    \n",
    "    clf = MLPClassifier(activation='logistic',\n",
    "                        solver='lbfgs',\n",
    "                        early_stopping=True,\n",
    "                        hidden_layer_sizes=(100,),\n",
    "                        random_state=seed)\n",
    "    trained = clf.fit(X, y)\n",
    "    \n",
    "    return trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicci칩n \n",
    "def prediction(X_test, trained):\n",
    "    y_pred = trained.predict(X_test)\n",
    "    y_pred_proba = trained.predict_proba(X_test)[:, 1]   # Se indican las prob de predecir la clase 1\n",
    "    return y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partici칩n estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(quakes_features, target, test_size=0.3,\n",
    "                                                    random_state=1, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Resultados de m칠tricas evaluadas con Random Forest:\n",
       "</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent: 0.53s\r",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "no provoca tsunami       0.93      0.93      0.93      1278\n",
      "s칤 provoca tsunami       0.55      0.58      0.57       201\n",
      "\n",
      "       avg / total       0.88      0.88      0.88      1479\n",
      "\n",
      "Accuracy:  0.8796484110885734 \n",
      "\n",
      "Matriz de Confusi칩n:\n",
      "\n",
      " [[1184   94]\n",
      " [  84  117]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "display(HTML('<h3> Resultados de m칠tricas evaluadas con Random Forest:\\n</h3>'))\n",
    "\n",
    "trained = fitRandomForest(X_train, y_train, seed=1)\n",
    "y_pred, y_pred_proba = prediction(X_test, trained)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['no provoca tsunami', 's칤 provoca tsunami']))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred), '\\n')   ## accuracy\n",
    "print('Matriz de Confusi칩n:\\n\\n', confusion_matrix(y_test, y_pred), '\\n')   ## Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Resultados de m칠tricas evaluadas con Regresion Log칤stica\n",
       "</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent: 0.04s\r",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "no provoca tsunami       0.94      0.78      0.85      1278\n",
      "s칤 provoca tsunami       0.33      0.70      0.45       201\n",
      "\n",
      "       avg / total       0.86      0.77      0.80      1479\n",
      "\n",
      "Accuracy:  0.7660581473968898 \n",
      "\n",
      "Matriz de Confusi칩n:\n",
      "\n",
      " [[993 285]\n",
      " [ 61 140]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# REGRESION LOG칈STICA\n",
    "display(HTML('<h3> Resultados de m칠tricas evaluadas con Regresion Log칤stica\\n</h3>'))\n",
    "\n",
    "trained = fitRegresionLogistica(X_train, y_train, 1)\n",
    "y_pred, y_pred_proba = prediction(X_test, trained)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['no provoca tsunami', 's칤 provoca tsunami']))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred), '\\n')   ## accuracy\n",
    "print('Matriz de Confusi칩n:\\n\\n', confusion_matrix(y_test, y_pred), '\\n')   ## Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Resultados de m칠tricas evaluadas con Support Vector Machine\n",
       "</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent: 1.58s\r",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "no provoca tsunami       0.86      0.51      0.64      1278\n",
      "s칤 provoca tsunami       0.13      0.46      0.20       201\n",
      "\n",
      "       avg / total       0.76      0.50      0.58      1479\n",
      "\n",
      "Accuracy:  0.49966193373901285 \n",
      "\n",
      "Matriz de Confusi칩n:\n",
      "\n",
      " [[647 631]\n",
      " [109  92]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MAQUINA DE VECTORES DE SOPORTE\n",
    "display(HTML('<h3> Resultados de m칠tricas evaluadas con Support Vector Machine\\n</h3>'))\n",
    "\n",
    "trained = fitSupportVectorMachine(X_train, y_train, C=3, seed=1)\n",
    "y_pred, y_pred_proba = prediction(X_test, trained)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['no provoca tsunami', 's칤 provoca tsunami']))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred), '\\n')   ## accuracy\n",
    "print('Matriz de Confusi칩n:\\n\\n', confusion_matrix(y_test, y_pred), '\\n')   ## Matriz de Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC, es un clasificador que trata de encontrar un hiperplano divisor de los datos. Como podemos intuir de la naturaleza de los datos, estos no son separables por un hiperplano, por lo que es esperable que este clasificador tenga un mal rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Resultados de m칠tricas evaluadas con Multilayer Perceptron\n",
       "</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent: 4.32s\r",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "no provoca tsunami       0.88      0.97      0.92      1278\n",
      "s칤 provoca tsunami       0.42      0.14      0.21       201\n",
      "\n",
      "       avg / total       0.82      0.86      0.82      1479\n",
      "\n",
      "Accuracy:  0.8573360378634213 \n",
      "\n",
      "Matriz de Confusi칩n:\n",
      "\n",
      " [[1240   38]\n",
      " [ 173   28]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RED NEURONAL\n",
    "display(HTML('<h3> Resultados de m칠tricas evaluadas con Multilayer Perceptron\\n</h3>'))\n",
    "\n",
    "trained = fitNeuralNetwork(X_train, y_train)\n",
    "y_pred, y_pred_proba = prediction(X_test, trained)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['no provoca tsunami', 's칤 provoca tsunami']))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred), '\\n')   ## accuracy\n",
    "print('Matriz de Confusi칩n:\\n\\n', confusion_matrix(y_test, y_pred), '\\n')   ## Matriz de Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del modelo Random Forest queremos aumentar el Recall, para detectar casos en que aparezca la clase minoritaria. Es decir, queremos aumentar la cantidad de casos en que se predice un tsunami, dado que efectivamente ocurrir치.\n",
    "\n",
    "Al incluir el par치metro class_weight='balanced' en la Regresi칩n Log칤stica, las clases adquieren un peso inversamente proporcional a la frecuencia de la clase. Como tenemos una base de datos desbalanceada, los valores 1 de la clase adquieren un peso mayor a los valores 0. Los resultados de esto indican que hay un aumento en el Recall, es decir, se han predicho correctamente un 82,23 % de los Tsunamis que han ocurrido. Esto es un avance, si se considera que con el modelo Random Forest se obtuvo un Recall cercano al 29,3 %. Sin embargo, la Precisi칩n del modelo baj칩 notablemente a un 16,29 %, por lo que ahora se est치n prediciendo muchos m치s tsunamis de los que efectivamente ocurrieron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Subsampling\n",
    "Para poder definir mejor el rendimiento de los modelos, definiremos la funci칩n de Random Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM SUBSAMPLING #\n",
    "\n",
    "def RandomSubsampling(X_train, y_train, X_test, y_test, B, model=fitRandomForest, seed=None):\n",
    "    \n",
    "    lista_fscore = []\n",
    "    lista_recall = []\n",
    "    lista_precision = []\n",
    "    lista_accuracy = []\n",
    "    \n",
    "    for i in range(B):\n",
    "        trained = model(X_train, y_train, seed)    # Se eval칰a modelo de Random Forest\n",
    "        y_pred, y_proba = prediction(X_test, trained)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred, average='binary')   ## recall\n",
    "        precision = precision_score(y_test, y_pred, average='binary')   ## precision\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)       ## F-score\n",
    "        accuracy = accuracy_score(y_test, y_pred)   ## accuracy\n",
    "        \n",
    "        lista_fscore.append(f_score)\n",
    "        lista_recall.append(recall)\n",
    "        lista_precision.append(precision)\n",
    "        lista_accuracy.append(accuracy)\n",
    "    \n",
    "    return lista_fscore, lista_recall, lista_precision, lista_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para corregir el problema de clases desbalanceada, se utilizar치 Up-sample Minority Class. Este proceso consiste en aumentar la cantidad de observaciones con la clase minoritaria (en este caso, que ocurra un Tsunami i.e. '1'). Este aumento se da gracias a la duplicaci칩n de estos datos de forma aleatoria. Se duplicar치n observaciones con reemplazo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up-sample Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4259\n",
       "1     671\n",
       "Name: tsunami, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "quakes_df['tsunami'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_class(X_train, y_train):\n",
    "    train = X_train.join(y_train)\n",
    "\n",
    "    # Se separa la base de datos en dos partes; una solo con eventos de tsunami y otra sin tsunamis.\n",
    "\n",
    "    major = train[train.tsunami == 0] \n",
    "    minor = train[train.tsunami == 1]\n",
    "\n",
    "    # Se duplican los datos de la clase minoritaria en la misma cantidad que en la clase mayoritaria\n",
    "\n",
    "    minor_sampled = resample(minor, replace=True, n_samples=len(major), random_state=1)\n",
    "\n",
    "    # Se crea la nueva base de datos con la base de la clase mayoritaria y la base minoritaria sampleada\n",
    "\n",
    "    quakes_sampled = pd.concat([major, minor_sampled])\n",
    "    print(quakes_sampled['tsunami'].value_counts())\n",
    "\n",
    "    qk_sampled_X = quakes_sampled[['latitude', 'longitude', 'depth', 'mag']]\n",
    "    qk_sampled_y = quakes_sampled['tsunami']\n",
    "    \n",
    "    return qk_sampled_X, qk_sampled_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC\n",
    "\n",
    "Indica la relaci칩n entre falsos positivos y verdaderos positivos en un algoritmo de clasificaci칩n binaria. Es una forma m치s did치ctica y gr치fica para comparara resultados de distintos modelos de clasificaci칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qk_sampled_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e08ed3820f2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Random Forest con partici칩n estratificada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrained1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqk_sampled_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk_sampled_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_proba1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qk_sampled_X' is not defined"
     ]
    }
   ],
   "source": [
    "# Considerando Up-Sample\n",
    "\n",
    "# Random Forest con partici칩n estratificada\n",
    "trained1 = fitRandomForest(qk_sampled_X, qk_sampled_y, 1)\n",
    "y_pred1, y_pred_proba1 = prediction(X_test, trained1)\n",
    "\n",
    "# Regresi칩n Log칤stica con partici칩n estratificada\n",
    "trained2 = fitRegresionLogistica(qk_sampled_X, qk_sampled_y, 1)\n",
    "y_pred2, y_pred_proba2 = prediction(X_test, trained2)\n",
    "\n",
    "# SVM con partici칩n estratificada\n",
    "trained3 = fitSupportVectorMachine(qk_sampled_X, qk_sampled_y, 1)\n",
    "y_pred3, y_pred_proba3 = prediction(X_test, trained3)\n",
    "\n",
    "# Red Neuronal con partici칩n estratificada\n",
    "trained4 = fitNeuralNetwork(qk_sampled_X, qk_sampled_y, 1)\n",
    "y_pred4, y_pred_proba4 = prediction(X_test, trained4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr: raz칩n de falsos positivos (tasa de predicci칩n de tsunamis, cuando no ocurrieron) -> 1 - Precision\n",
    "# tpr: raz칩n de verdaderos positivos (tasa de predicci칩n de tsunamis, cuando efectivamente hubo) -> Recall\n",
    "# tresholds: puntos en los que ser치n graficados los valores\n",
    "\n",
    "# y_test obtenido de la partici칩n estratificada e 'y_pred_proba' obtenido de aplicar un Random Forest con Up-Sampled\n",
    "\n",
    "fpr1, tpr1, thresholds1 = roc_curve(np.array(y_test), y_pred_proba1)\n",
    "fpr2, tpr2, thresholds2 = roc_curve(np.array(y_test), y_pred_proba2)\n",
    "fpr3, tpr3, thresholds3 = roc_curve(np.array(y_test), y_pred_proba3)\n",
    "fpr4, tpr4, thresholds4 = roc_curve(np.array(y_test), y_pred_proba4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr치fica ROC\n",
    "green_line = mlines.Line2D([fpr1], [tpr1], color='green', marker='|',\n",
    "                          markersize=17, label='Random Forest')\n",
    "red_line = mlines.Line2D([fpr2], [tpr2], color='red', marker='|',\n",
    "                          markersize=17, label='Logistic Regression')\n",
    "blue_line = mlines.Line2D([fpr3], [tpr3], color='blue', marker='|',\n",
    "                          markersize=17, label='Support Vector Machine')\n",
    "yellow_line = mlines.Line2D([fpr4], [tpr4], color='yellow', marker='|',\n",
    "                          markersize=17, label='Multilayer Perceptron')\n",
    "\n",
    "plt.plot([fpr1], [tpr1], 'g|', [fpr2], [tpr2], 'r|', [fpr3], [tpr3], 'b|', [fpr4], [tpr4], 'y|')\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.xlabel('Tasa de Falsos Positivos (1 - Precision)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (Recall)')\n",
    "plt.title('Curva ROC para Clasificador de Tsunamis')\n",
    "plt.legend(handles=[green_line, red_line, yellow_line, blue_line], bbox_to_anchor=(0.49, 0.33), loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividiendo el mapa\n",
    "Debido a que todos los algoritmos fallaban al predecir la presencia de tsunami con medidas de performance razonables, trataremos de dividir el mapamundi, para poder acotar el contexto de modelaci칩n, y as칤 tratar un conjunto de datos que quiz치s sea m치s separable que todos los datos juntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partiremos analizando el continente de america, que seg칰n el mapa anteriormente visualizado, estar칤a en el\n",
    "# siguiente intervalo:\n",
    "\n",
    "# america = quakes_df[(quakes_df['longitude'] < -50) & (quakes_df['longitude'] > -150)]\n",
    "# america = quakes_df[(quakes_df['longitude'] > -50) & (quakes_df['longitude'] < 75)]\n",
    "america = quakes_df[(quakes_df['longitude'] > 150)]\n",
    "x = america['longitude']\n",
    "y = america['latitude']\n",
    "\n",
    "area = 10\n",
    "plt.figure(figsize=(10, 8))\n",
    "max_mag, min_mag = max(america['mag']), min(america['mag'])\n",
    "area = (america['mag'] - min_mag) / (max_mag - min_mag) * 50\n",
    "\n",
    "plt.scatter(x, y, s=area, marker='o',\n",
    "            c=1 - america['tsunami'],\n",
    "            alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "america_features = america[['latitude', 'longitude', 'depth', 'mag']]\n",
    "america_target = america['tsunami']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partici칩n estratificada para america\n",
    "X_train_america, X_test_america, y_train_america, y_test_america = train_test_split(america_features,\n",
    "                                                                                    america_target,\n",
    "                                                                                    test_size=0.3,\n",
    "                                                                                    random_state=1,\n",
    "                                                                                    stratify=america_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST CON SOLO AMERICA\n",
    "display(HTML('<h3> Resultados de m칠tricas evaluadas con Random Forest:\\n</h3>'))\n",
    "\n",
    "trained = fitRandomForest(X_train_america, y_train_america, seed=1)\n",
    "y_pred, y_pred_proba = prediction(X_test, trained)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['no provoca tsunami', 's칤 provoca tsunami']))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred), '\\n')   ## accuracy\n",
    "print('Matriz de Confusi칩n:\\n\\n', confusion_matrix(y_test, y_pred), '\\n')   ## Matriz de Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la precisi칩n en en am칠rica con random forest sube mucho. Sin embargo, el recall es muy bajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGRESION LOG칈STICA CON AMERICA\n",
    "display(HTML('<h3> Resultados de m칠tricas evaluadas con Regresion Log칤stica\\n</h3>'))\n",
    "\n",
    "trained = fitRegresionLogistica(X_train_america, y_train_america, 1)\n",
    "y_pred, y_pred_proba = prediction(X_test, trained)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['no provoca tsunami', 's칤 provoca tsunami']))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred), '\\n')   ## accuracy\n",
    "print('Matriz de Confusi칩n:\\n\\n', confusion_matrix(y_test, y_pred), '\\n')   ## Matriz de Confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con regresion log칤stica, el recall es el que llega muy alto, mientras que la precision es muy mala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene el set de train\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(quakes_features, target, test_size=0.3, \n",
    "                                                    random_state=1, stratify=target)\n",
    "\n",
    "qk_sampled_X, qk_sampled_y = up_class(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eval칰a el modelo Random Forest con la nueva base de datos de entrenamiento mediante RandomSubsampling \n",
    "\n",
    "listaFscore, listaRecall, listaPrecision, listaAccuracy = RandomSubsampling(qk_sampled_X,\n",
    "                                                                            qk_sampled_y, \n",
    "                                                                            X_test,\n",
    "                                                                            y_test, 20,\n",
    "                                                                            seed=1,\n",
    "                                                                            model=fitRandomForest)\n",
    "\n",
    "f_score = sum(i for i in listaFscore)/len(listaFscore)\n",
    "recall = sum(i for i in listaRecall)/len(listaRecall)\n",
    "precision = sum(i for i in listaPrecision)/len(listaPrecision)\n",
    "accuracy = sum(i for i in listaAccuracy)/len(listaAccuracy)\n",
    "\n",
    "print('Precision: {:.2f}             \\nRecall: {:.2f}\\nF-score: {:.2f}\\nAccuracy: {:.2f}\\n'.format(precision, recall, f_score, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eval칰a el modelo Random Forest con la nueva base de datos de entrenamiento mediante RandomSubsampling \n",
    "\n",
    "listaFscore, listaRecall, listaPrecision, listaAccuracy = RandomSubsampling(qk_sampled_X,\n",
    "                                                                            qk_sampled_y, \n",
    "                                                                            X_test,\n",
    "                                                                            y_test, 20,\n",
    "                                                                            seed=1,\n",
    "                                                                            model=fitRegresionLogistica)\n",
    "\n",
    "f_score = sum(i for i in listaFscore)/len(listaFscore)\n",
    "recall = sum(i for i in listaRecall)/len(listaRecall)\n",
    "precision = sum(i for i in listaPrecision)/len(listaPrecision)\n",
    "accuracy = sum(i for i in listaAccuracy)/len(listaAccuracy)\n",
    "\n",
    "print('Precision: {:.2f}             \\nRecall: {:.2f}\\nF-score: {:.2f}\\nAccuracy: {:.2f}\\n'.format(precision, recall, f_score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve claramente en los resultados que la predicci칩n ha mejorado relativamente, al aplicar el modelo de Random Forest con Up-Sample Minority Class. El Recall ha aumentado de un 29,3 % a un ~ 81 %, sin embargo, la Precisi칩n se desplom칩 desde un 71,7 % a un 25,48 %. En cuanto a la Accuracy y F-Score, estos disminuyeron entre 4 y 5 puntos aproximadamente. Para efectos pr치cticos, pese a que al ocupar Up Sample Minority Class empeor칩 la predicci칩n, al ocupar este m칠todo se predice significativamente mejor los tsunamis que van a ocurrir. Esto es importante de considerar, ya que predecir un tsunami es muy importante para salvar vidas y lo anterior contribuye a poder determinar con rapidez medidas de contingencia. Desde otro punto de vista, dado que el modelo es poco preciso, tambi칠n se predicen muchos tsunamis cuando estos no ocurren, lo que puede ser perjudicial desde el punto de vista de costos, ya que en la pr치ctica se utilizar칤an muchos recursos de todo tipo en vano y habr칤an p칠rdidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
